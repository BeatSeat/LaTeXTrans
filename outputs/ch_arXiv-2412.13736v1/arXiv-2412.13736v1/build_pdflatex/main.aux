\relax 
\bibstyle{acl_natbib}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{zhang2023multimodal}
\citation{zhang2023multimodal}
\citation{chen2022align,gong2021cross,ren2020cgmvqa,khare2021mmbert}
\citation{liu2023parameter}
\citation{tiong2022plug,banerjee2020weaqa,changpinyo2022all,liu2023chatgpt,gai2024medthink}
\citation{nguyen2019overcoming}
\citation{kim2018bilinear}
\citation{zhan2020medical}
\citation{eslami2021does,song2022clip,wang2022clip}
\citation{eslami2021does}
\citation{nguyen2019overcoming}
\citation{pelka2018radiology}
\citation{liu2023parameter}
\citation{li2024llava}
\@writefile{toc}{\contentsline {section}{\numberline {1}引言}{1}{section.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  上图显示了先前 Med-VQA 方法与 MedCoT 的输出比较，以及 MMCoT 中的先前技术 \citep  {zhang2023multimodal} 与 MedCoT 中的稀疏 MoE 的比较。 下图展示了 MedCoT 模型规模约为 256M 参数，在 VQA-RAD 和 SLAKE-EN 数据集上的准确率分别超越 7B 参数的 LLaVA-Med 5.52\% 和 4.09\%。 }}{1}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig1}{{1}{1}{上图显示了先前 Med-VQA 方法与 MedCoT 的输出比较，以及 MMCoT 中的先前技术 \cite {zhang2023multimodal} 与 MedCoT 中的稀疏 MoE 的比较。 下图展示了 MedCoT 模型规模约为 256M 参数，在 VQA-RAD 和 SLAKE-EN 数据集上的准确率分别超越 7B 参数的 LLaVA-Med 5.52\% 和 4.09\%。}{figure.caption.1}{}}
\citation{nguyen2019overcoming,liu2023parameter,zhan2020medical}
\citation{zhang2023multimodal,zheng2023ddcot}
\citation{zhang2023multimodal,zheng2023ddcot}
\citation{zhang2023multimodal}
\citation{ben2019vqa,he2020pathvqa,ren2020cgmvqa}
\citation{liu2023parameter}
\citation{nguyen2019overcoming}
\citation{zhan2020medical}
\citation{eslami-etal-2023-pubmedclip}
\citation{li2024llava}
\citation{zhang2023multimodal,zheng2023ddcot}
\citation{zheng2023ddcot,zhang2023multimodal,lu2022learn,lu2023chameleon,zhang2023llama}
\citation{lu2022learn}
\citation{lu2022learn}
\citation{zheng2023ddcot}
\citation{zhang2024scalable,fedus2022switch}
\citation{shazeer2016outrageously}
\citation{jacobs1991adaptive,fedus2022review}
\citation{shazeer2016outrageously}
\citation{lepikhin2020gshard}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  MedCoT 流程首先由初始专家接收医疗问题和图像，以生成初步推理。该推理可能存在缺陷（用红色标记），随后由后续专家进行审查。如果推理被认为有效，则保留；否则，将重新考虑，并生成新的推理（用绿色标记），以及图像说明。然后将这些元素整合到诊断专家中。在所有背景信息的指导下，诊断专家作为一种设计了稀疏 MoE 结构的多模态语言模型，给出最终诊断结果（答案）。 }}{3}{figure.caption.2}\protected@file@percent }
\newlabel{MedCoT pipeline}{{2}{3}{MedCoT 流程首先由初始专家接收医疗问题和图像，以生成初步推理。该推理可能存在缺陷（用红色标记），随后由后续专家进行审查。如果推理被认为有效，则保留；否则，将重新考虑，并生成新的推理（用绿色标记），以及图像说明。然后将这些元素整合到诊断专家中。在所有背景信息的指导下，诊断专家作为一种设计了稀疏 MoE 结构的多模态语言模型，给出最终诊断结果（答案）。}{figure.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}相关工作}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Med-VQA}{3}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}多模态链式推理}{3}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}MoE}{3}{subsection.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces 诊断专家流程。 医学图像通过视觉编码器后生成视觉特征。 包括图像标题、推理过程和选项在内的上下文文本信息通过文本编码器处理，以获取文本特征。 然后通过交叉注意进行特征整合，产生组合特征。 这些整合特征与文本特征一起输入到稀疏 MoE 结构中。 在这里，多个专业专家深入理解图像和文本的意图。 然后将这些理解输入到文本解码器中，解码信息以产生最终答案。 }}{4}{figure.caption.3}\protected@file@percent }
\newlabel{Diagnostic}{{3}{4}{诊断专家流程。 医学图像通过视觉编码器后生成视觉特征。 包括图像标题、推理过程和选项在内的上下文文本信息通过文本编码器处理，以获取文本特征。 然后通过交叉注意进行特征整合，产生组合特征。 这些整合特征与文本特征一起输入到稀疏 MoE 结构中。 在这里，多个专业专家深入理解图像和文本的意图。 然后将这些理解输入到文本解码器中，解码信息以产生最终答案。}{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}方法论}{4}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}预备知识}{4}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}初始专家}{4}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}后续专家}{4}{subsection.3.3}\protected@file@percent }
\citation{zhang2023multimodal,zheng2023ddcot}
\citation{fedus2022switch}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}诊断专家}{5}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}多模态 T5}{5}{subsubsection.3.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2}MoE}{5}{subsubsection.3.4.2}\protected@file@percent }
\citation{khashabi2020unifiedqa,raffel2020exploring}
\citation{carion2020end}
\citation{lau2018dataset}
\citation{liu2021slake}
\citation{abacha2019vqa}
\citation{he2020pathvqa}
\citation{paszke2019pytorch}
\citation{wolf2020transformers}
\citation{nguyen2019overcoming}
\citation{tiong-etal-2022-plug}
\citation{eslami-etal-2023-pubmedclip}
\citation{liu2023parameter}
\citation{gai2024medthink}
\citation{li2024llava}
\citation{gai2024medthink}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces  MedCoT 与多种 SoTA 方法在 VQA-RAD 和 SLAKE-EN 数据集的封闭问题上进行比较。 MedCoT 不仅在答案上达到 SoTA 准确率，还提供推理路径（理由）。 使用的指标是准确率（\%）。 }}{6}{figure.caption.4}\protected@file@percent }
\newlabel{performance}{{4}{6}{MedCoT 与多种 SoTA 方法在 VQA-RAD 和 SLAKE-EN 数据集的封闭问题上进行比较。 MedCoT 不仅在答案上达到 SoTA 准确率，还提供推理路径（理由）。 使用的指标是准确率（\%）。}{figure.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}实验}{6}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}实验设置}{6}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}主要结果}{6}{subsection.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces  MedCoT 管道从初始专家接收医疗问题和图像开始，以生成初步推理。该推理可能存在缺陷（用红色表示），随后由跟进专家进行审查。如果推理被认为有效，则保留；否则，将重新考虑并生成新的推理（用绿色表示），以及图像说明。这些元素随后会被整合到诊断专家中。在所有背景信息的指导下，诊断专家作为一个具有设计稀疏 MoE 结构的多模态语言模型，提供最终的诊断结果（答案）。 }}{7}{figure.caption.5}\protected@file@percent }
\newlabel{case1}{{5}{7}{MedCoT 管道从初始专家接收医疗问题和图像开始，以生成初步推理。该推理可能存在缺陷（用红色表示），随后由跟进专家进行审查。如果推理被认为有效，则保留；否则，将重新考虑并生成新的推理（用绿色表示），以及图像说明。这些元素随后会被整合到诊断专家中。在所有背景信息的指导下，诊断专家作为一个具有设计稀疏 MoE 结构的多模态语言模型，提供最终的诊断结果（答案）。}{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces  诊断专家的稀疏 MoE 在 VQA-RAD 中对不同器官相关问题显示出不同的准确性水平。 'ABD' 代表腹部相关问题，'Head' 指头部相关问题，'Chest' 指胸部相关问题。 可以观察到头部相关问题的准确率提高了近 10 \%。我们可视化了专家的权重（右图）。值得注意的是，在前 2 个专家选择中，模型选择了专家 0 和专家 5 来理解“头部”图像和文本的意图。 }}{7}{figure.caption.6}\protected@file@percent }
\newlabel{rad}{{6}{7}{诊断专家的稀疏 MoE 在 VQA-RAD 中对不同器官相关问题显示出不同的准确性水平。 'ABD' 代表腹部相关问题，'Head' 指头部相关问题，'Chest' 指胸部相关问题。 可以观察到头部相关问题的准确率提高了近 10 \%。我们可视化了专家的权重（右图）。值得注意的是，在前 2 个专家选择中，模型选择了专家 0 和专家 5 来理解“头部”图像和文本的意图。}{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}消融研究}{7}{subsection.4.3}\protected@file@percent }
\newlabel{ablation}{{4.3}{7}{消融研究}{subsection.4.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces 关于 MedCoT 的消融研究}}{7}{table.caption.8}\protected@file@percent }
\newlabel{xiaorong}{{1}{7}{关于 MedCoT 的消融研究}{table.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces 在两个数据集上的专家数量网格搜索。蓝线表示使用初始专家推理进行训练以及在诊断专家中进行专家数量网格搜索的结果。紫线表示使用后续专家推理并进行专家数量网格搜索的结果。灰线表示诊断专家在没有稀疏 MoE 情况下使用后续专家推理的结果。}}{8}{figure.caption.7}\protected@file@percent }
\newlabel{zhexiantu-all}{{7}{8}{在两个数据集上的专家数量网格搜索。蓝线表示使用初始专家推理进行训练以及在诊断专家中进行专家数量网格搜索的结果。紫线表示使用后续专家推理并进行专家数量网格搜索的结果。灰线表示诊断专家在没有稀疏 MoE 情况下使用后续专家推理的结果。}{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}讨论}{8}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}结论}{8}{section.5}\protected@file@percent }
\bibdata{main}
\bibcite{abacha2019vqa}{{1}{2019}{{Abacha et~al.}}{{Abacha, Hasan, Datla, Liu, Demner-Fushman, and M{\"u}ller}}}
\bibcite{banerjee2020weaqa}{{2}{2021}{{Banerjee et~al.}}{{Banerjee, Gokhale, Yang, and Baral}}}
\bibcite{ben2019vqa}{{3}{2019}{{Ben~Abacha et~al.}}{{Ben~Abacha, Hasan, Datla, Demner-Fushman, and M{\"u}ller}}}
\bibcite{carion2020end}{{4}{2020}{{Carion et~al.}}{{Carion, Massa, Synnaeve, Usunier, Kirillov, and Zagoruyko}}}
\bibcite{changpinyo2022all}{{5}{2022}{{Changpinyo et~al.}}{{Changpinyo, Kukliansy, Szpektor, Chen, Ding, and Soricut}}}
\bibcite{chen2022align}{{6}{2022}{{Chen et~al.}}{{Chen, Li, and Wan}}}
\bibcite{eslami2021does}{{7}{2021}{{Eslami et~al.}}{{Eslami, de~Melo, and Meinel}}}
\bibcite{eslami-etal-2023-pubmedclip}{{8}{2023}{{Eslami et~al.}}{{Eslami, Meinel, and de~Melo}}}
\bibcite{fedus2022review}{{9}{2022{a}}{{Fedus et~al.}}{{Fedus, Dean, and Zoph}}}
\bibcite{fedus2022switch}{{10}{2022{b}}{{Fedus et~al.}}{{Fedus, Zoph, and Shazeer}}}
\bibcite{gai2024medthink}{{11}{2024}{{Gai et~al.}}{{Gai, Zhou, Liu, Feng, Wu, and Liu}}}
\bibcite{gong2021cross}{{12}{2021}{{Gong et~al.}}{{Gong, Chen, Liu, Yu, and Li}}}
\bibcite{he2020pathvqa}{{13}{2020}{{He et~al.}}{{He, Zhang, Mou, Xing, and Xie}}}
\bibcite{jacobs1991adaptive}{{14}{1991}{{Jacobs et~al.}}{{Jacobs, Jordan, Nowlan, and Hinton}}}
\bibcite{khare2021mmbert}{{15}{2021}{{Khare et~al.}}{{Khare, Bagal, Mathew, Devi, Priyakumar, and Jawahar}}}
\bibcite{khashabi2020unifiedqa}{{16}{2020}{{Khashabi et~al.}}{{Khashabi, Min, Khot, Sabharwal, Tafjord, Clark, and Hajishirzi}}}
\bibcite{kim2018bilinear}{{17}{2018}{{Kim et~al.}}{{Kim, Jun, and Zhang}}}
\bibcite{lau2018dataset}{{18}{2018}{{Lau et~al.}}{{Lau, Gayen, Ben~Abacha, and Demner-Fushman}}}
\bibcite{lepikhin2020gshard}{{19}{2020}{{Lepikhin et~al.}}{{Lepikhin, Lee, Xu, Chen, Firat, Huang, Krikun, Shazeer, and Chen}}}
\bibcite{li2024llava}{{20}{2024}{{Li et~al.}}{{Li, Wong, Zhang, Usuyama, Liu, Yang, Naumann, Poon, and Gao}}}
\bibcite{liu2021slake}{{21}{2021}{{Liu et~al.}}{{Liu, Zhan, Xu, Ma, Yang, and Wu}}}
\bibcite{liu2023parameter}{{22}{2023{a}}{{Liu et~al.}}{{Liu, Hu, Zhang, Feng, Hao, Lv, and Liu}}}
\bibcite{liu2023chatgpt}{{23}{2023{b}}{{Liu et~al.}}{{Liu, Hu, Zhang, Gai, FENG, and Liu}}}
\bibcite{lu2022learn}{{24}{2022}{{Lu et~al.}}{{Lu, Mishra, Xia, Qiu, Chang, Zhu, Tafjord, Clark, and Kalyan}}}
\bibcite{lu2023chameleon}{{25}{2023}{{Lu et~al.}}{{Lu, Peng, Cheng, Galley, Chang, Wu, Zhu, and Gao}}}
\bibcite{nguyen2019overcoming}{{26}{2019}{{Nguyen et~al.}}{{Nguyen, Do, Nguyen, Do, Tjiputra, and Tran}}}
\bibcite{paszke2019pytorch}{{27}{2019}{{Paszke et~al.}}{{Paszke, Gross, Massa, Lerer, Bradbury, Chanan, Killeen, Lin, Gimelshein, Antiga et~al.}}}
\bibcite{pelka2018radiology}{{28}{2018}{{Pelka et~al.}}{{Pelka, Koitka, R{\"u}ckert, Nensa, and Friedrich}}}
\bibcite{raffel2020exploring}{{29}{2020}{{Raffel et~al.}}{{Raffel, Shazeer, Roberts, Lee, Narang, Matena, Zhou, Li, and Liu}}}
\bibcite{ren2020cgmvqa}{{30}{2020}{{Ren and Zhou}}{{}}}
\bibcite{shazeer2016outrageously}{{31}{2016}{{Shazeer et~al.}}{{Shazeer, Mirhoseini, Maziarz, Davis, Le, Hinton, and Dean}}}
\bibcite{song2022clip}{{32}{2022}{{Song et~al.}}{{Song, Dong, Zhang, Liu, and Wei}}}
\bibcite{tiong2022plug}{{33}{2022{a}}{{Tiong et~al.}}{{Tiong, Li, Li, Savarese, and Hoi}}}
\bibcite{tiong-etal-2022-plug}{{34}{2022{b}}{{Tiong et~al.}}{{Tiong, Li, Li, Savarese, and Hoi}}}
\bibcite{wang2022clip}{{35}{2022}{{Wang et~al.}}{{Wang, Xiao, Codella, Yang, Chen, Zhou, Chang, Dai, You, and Yuan}}}
\bibcite{wolf2020transformers}{{36}{2020}{{Wolf et~al.}}{{Wolf, Debut, Sanh, Chaumond, Delangue, Moi, Cistac, Rault, Louf, Funtowicz et~al.}}}
\bibcite{zhan2020medical}{{37}{2020}{{Zhan et~al.}}{{Zhan, Liu, Fan, Chen, and Wu}}}
\bibcite{zhang2023llama}{{38}{2023{a}}{{Zhang et~al.}}{{Zhang, Han, Zhou, Hu, Yan, Lu, Li, Gao, and Qiao}}}
\bibcite{zhang2024scalable}{{39}{2024}{{Zhang et~al.}}{{Zhang, Liu, Li, Dong, Fu, and Wu}}}
\bibcite{zhang2023multimodal}{{40}{2023{b}}{{Zhang et~al.}}{{Zhang, Zhang, Li, Zhao, Karypis, and Smola}}}
\bibcite{zheng2023ddcot}{{41}{2023}{{Zheng et~al.}}{{Zheng, Yang, Tang, Zhou, and Yang}}}
\gdef \@abspage@last{11}
