\relax 
\providecommand\zref@newlabel[2]{}
\providecommand \babel@aux [2]{\global \let \babel@toc \@gobbletwo }
\@nameuse{bbl@beforestart}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{abbrvnat}
\providecommand \oddpage@label [2]{}
\babel@aux{english}{}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  \centering  DeepSeek-R1{} 的基准性能。 }}{1}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:dsv3_performance}{{1}{1}{\centering \dsri {} 的基准性能。}{figure.caption.1}{}}
\citation{gpt4o,claude35sonnet,gemini1_5}
\citation{o1}
\citation{uesato2022solving,lightman2023let,mathshepherd}
\citation{kumar2024training}
\citation{feng2024alphazeroliketreesearchguidelarge,xin2024deepseekproverv15harnessingproofassistant,AlphaGeometryTrinh2024}
\citation{deepseekmath}
\citation{qwen2_5}
\citation{llama3}
\citation{QwQ}
\@writefile{toc}{\contentsline {section}{\numberline {1}介绍}{3}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}贡献}{3}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{后训练：在基础模型上进行大规模强化学习}{3}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{蒸馏：小模型也可以很强大}{4}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}评估结果总结}{4}{subsection.1.2}\protected@file@percent }
\citation{mathshepherd,deepseekmath}
\citation{deepseekmath}
\@writefile{toc}{\contentsline {section}{\numberline {2}方法}{5}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}概述}{5}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2} DeepSeek-R1-Zero{}: 基于模型的强化学习}{5}{subsection.2.2}\protected@file@percent }
\newlabel{sec:ds-zero}{{2.2}{5}{ \dsro {}: 基于模型的强化学习}{subsection.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}强化学习算法}{5}{subsubsection.2.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{群体相对策略优化}{5}{subsubsection.2.2.1}\protected@file@percent }
\newlabel{eq:GRPO-obj}{{1}{5}{群体相对策略优化}{equation.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces  DeepSeek-R1-Zero{} 的模板。 \textcolor {red}{prompt} 将在训练中被特定的推理问题替换。}}{6}{table.caption.2}\protected@file@percent }
\newlabel{tab:r0_template}{{1}{6}{\dsro {} 的模板。 \textcolor {red}{prompt} 将在训练中被特定的推理问题替换。}{table.caption.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces 在推理相关基准测试中 DeepSeek-R1-Zero{} 和 OpenAI o1 模型的比较。}}{6}{table.caption.3}\protected@file@percent }
\newlabel{tab:r1-zero}{{2}{6}{在推理相关基准测试中 \dsro {} 和 OpenAI o1 模型的比较。}{table.caption.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}奖励建模}{6}{subsubsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}训练模板}{6}{subsubsection.2.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4}DeepSeek-R1-Zero{} 的性能、自我进化过程和顿悟时刻}{6}{subsubsection.2.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{DeepSeek-R1-Zero{} 的性能}{6}{subsubsection.2.2.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces DeepSeek-R1-Zero{} 在训练期间的 AIME 准确性。对于每个问题，我们采样 16 个回答并计算总体平均准确性，以确保评估的稳定性。}}{7}{figure.caption.4}\protected@file@percent }
\newlabel{fig:zero-training-performance}{{2}{7}{\dsro {} 在训练期间的 AIME 准确性。对于每个问题，我们采样 16 个回答并计算总体平均准确性，以确保评估的稳定性。}{figure.caption.4}{}}
\@writefile{toc}{\contentsline {paragraph}{DeepSeek-R1-Zero{} 的自我进化过程}{7}{figure.caption.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces DeepSeek-R1-Zero{} 在训练集上的平均响应长度在 RL 过程中的变化。 DeepSeek-R1-Zero{} 自然地学习在推理任务中使用更多的思考时间。}}{8}{figure.caption.5}\protected@file@percent }
\newlabel{fig:zero-training-length}{{3}{8}{\dsro {} 在训练集上的平均响应长度在 RL 过程中的变化。 \dsro {} 自然地学习在推理任务中使用更多的思考时间。}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {paragraph}{DeepSeek-R1-Zero{} 的顿悟时刻}{8}{figure.caption.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{DeepSeek-R1-Zero{} 的缺陷}{8}{figure.caption.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}DeepSeek-R1{}: 冷启动下的强化学习}{8}{subsection.2.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces 一个有趣的 DeepSeek-R1-Zero{} 中间版本的 ``aha 时刻''。模型学会用拟人化的语气重新思考。这对我们来说也是一个 aha 时刻，让我们见证了强化学习的力量和美妙。}}{9}{table.caption.6}\protected@file@percent }
\newlabel{tab:aha_moment}{{3}{9}{一个有趣的 \dsro {} 中间版本的 ``aha 时刻''。模型学会用拟人化的语气重新思考。这对我们来说也是一个 aha 时刻，让我们见证了强化学习的力量和美妙。}{table.caption.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}冷启动}{9}{subsubsection.2.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}面向推理的强化学习}{10}{subsubsection.2.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3}拒绝采样与监督微调}{10}{subsubsection.2.3.3}\protected@file@percent }
\newlabel{sec:method:r1:sft}{{2.3.3}{10}{拒绝采样与监督微调}{subsubsection.2.3.3}{}}
\@writefile{toc}{\contentsline {paragraph}{推理数据}{10}{subsubsection.2.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{非推理数据}{10}{subsubsection.2.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.4}所有场景的强化学习}{10}{subsubsection.2.3.4}\protected@file@percent }
\citation{qwen2_5}
\citation{llama3_1_405b}
\citation{mmlu}
\citation{mmlu_redux}
\citation{mmlu_pro}
\citation{ceval}
\citation{cmmlu}
\citation{IFeval}
\citation{frames}
\citation{gpqa}
\citation{simpleqa}
\citation{csimpleqa}
\citation{swe_verified}
\citation{livecodebench}
\citation{AIME2024}
\citation{alpaca2.0}
\citation{li2024crowdsourced}
\citation{Lin_ZeroEval_A_Unified_2024}
\citation{agentless}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}蒸馏：赋予小模型推理能力}{11}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}实验}{11}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{基准测试}{11}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{评估提示}{11}{section.3}\protected@file@percent }
\citation{QwQ}
\citation{codex}
\citation{wang2022self}
\@writefile{toc}{\contentsline {paragraph}{基线}{12}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{评估设置}{12}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}DeepSeek-R1{} 评估}{12}{subsection.3.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces  DeepSeek-R1{} 与其他典型模型的比较。 }}{13}{table.caption.7}\protected@file@percent }
\newlabel{tab:main}{{4}{13}{\dsri {} 与其他典型模型的比较。}{table.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}蒸馏模型评估}{13}{subsection.3.2}\protected@file@percent }
\newlabel{sec:distilled_model_evaluation}{{3.2}{13}{蒸馏模型评估}{subsection.3.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces DeepSeek-R1 蒸馏模型与其他可比较模型在推理相关基准上的比较。}}{14}{table.caption.8}\protected@file@percent }
\newlabel{tab:distill}{{5}{14}{DeepSeek-R1 蒸馏模型与其他可比较模型在推理相关基准上的比较。}{table.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}讨论}{14}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}蒸馏与强化学习}{14}{subsection.4.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces \centering  蒸馏模型和 RL 模型在推理相关基准上的比较。}}{14}{table.caption.9}\protected@file@percent }
\newlabel{tab:distill_vs_rl}{{6}{14}{\centering 蒸馏模型和 RL 模型在推理相关基准上的比较。}{table.caption.9}{}}
\citation{uesato2022solving,lightman2023let,mathshepherd}
\citation{gao2022scalinglawsrewardmodel}
\citation{snell2024scalingllmtesttimecompute}
\citation{alphago}
\citation{alphazero}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}不成功的尝试}{15}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{过程奖励模型 (PRM)}{15}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{蒙特卡罗树搜索 (MCTS)}{15}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}结论、局限性与未来工作}{15}{section.5}\protected@file@percent }
\bibdata{main}
\bibcite{llama3_1_405b}{{1}{2024}{{AI@Meta}}{{}}}
\bibcite{claude35sonnet}{{2}{2024}{{Anthropic}}{{}}}
\bibcite{codex}{{3}{2021}{{Chen et~al.}}{{Chen, Tworek, Jun, Yuan, de~Oliveira~Pinto, Kaplan, Edwards, Burda, Joseph, Brockman, Ray, Puri, Krueger, Petrov, Khlaaf, Sastry, Mishkin, Chan, Gray, Ryder, Pavlov, Power, Kaiser, Bavarian, Winter, Tillet, Such, Cummings, Plappert, Chantzis, Barnes, Herbert{-}Voss, Guss, Nichol, Paino, Tezak, Tang, Babuschkin, Balaji, Jain, Saunders, Hesse, Carr, Leike, Achiam, Misra, Morikawa, Radford, Knight, Brundage, Murati, Mayer, Welinder, McGrew, Amodei, McCandlish, Sutskever, and Zaremba}}}
\bibcite{llama3}{{4}{2024}{{Dubey et~al.}}{{Dubey, Jauhri, Pandey, Kadian, Al-Dahle, Letman, Mathur, Schelten, Yang, Fan, et~al.}}}
\bibcite{alpaca2.0}{{5}{2024}{{Dubois et~al.}}{{Dubois, Galambosi, Liang, and Hashimoto}}}
\bibcite{feng2024alphazeroliketreesearchguidelarge}{{6}{2024}{{Feng et~al.}}{{Feng, Wan, Wen, McAleer, Wen, Zhang, and Wang}}}
\bibcite{gao2022scalinglawsrewardmodel}{{7}{2022}{{Gao et~al.}}{{Gao, Schulman, and Hilton}}}
\bibcite{mmlu_redux}{{8}{2024}{{Gema et~al.}}{{Gema, Leang, Hong, Devoto, Mancino, Saxena, He, Zhao, Du, Madani, Barale, McHardy, Harris, Kaddour, van Krieken, and Minervini}}}
\bibcite{gemini1_5}{{9}{2024}{{Google}}{{}}}
\bibcite{csimpleqa}{{10}{2024}{{He et~al.}}{{He, Li, Liu, Tan, Wang, Huang, Bu, Guo, Hu, Zheng, et~al.}}}
\bibcite{mmlu}{{11}{2020}{{Hendrycks et~al.}}{{Hendrycks, Burns, Basart, Zou, Mazeika, Song, and Steinhardt}}}
\bibcite{ceval}{{12}{2023}{{Huang et~al.}}{{Huang, Bai, Zhu, Zhang, Zhang, Su, Liu, Lv, Zhang, Lei, et~al.}}}
\bibcite{livecodebench}{{13}{2024}{{Jain et~al.}}{{Jain, Han, Gu, Li, Yan, Zhang, Wang, Solar{-}Lezama, Sen, and Stoica}}}
\bibcite{frames}{{14}{2024}{{Krishna et~al.}}{{Krishna, Krishna, Mohananey, Schwarcz, Stambler, Upadhyay, and Faruqui}}}
\bibcite{kumar2024training}{{15}{2024}{{Kumar et~al.}}{{Kumar, Zhuang, Agarwal, Su, Co-Reyes, Singh, Baumli, Iqbal, Bishop, Roelofs, et~al.}}}
\bibcite{cmmlu}{{16}{2023}{{Li et~al.}}{{Li, Zhang, Koto, Yang, Zhao, Gong, Duan, and Baldwin}}}
\bibcite{li2024crowdsourced}{{17}{2024}{{Li et~al.}}{{Li, Chiang, Frick, Dunlap, Wu, Zhu, Gonzalez, and Stoica}}}
\bibcite{lightman2023let}{{18}{2023}{{Lightman et~al.}}{{Lightman, Kosaraju, Burda, Edwards, Baker, Lee, Leike, Schulman, Sutskever, and Cobbe}}}
\bibcite{Lin_ZeroEval_A_Unified_2024}{{19}{2024}{{Lin}}{{}}}
\bibcite{AIME2024}{{20}{2024}{{MAA}}{{}}}
\bibcite{gpt4o}{{21}{2024{a}}{{OpenAI}}{{}}}
\bibcite{o1}{{22}{2024{b}}{{OpenAI}}{{}}}
\bibcite{simpleqa}{{23}{2024{c}}{{OpenAI}}{{}}}
\bibcite{swe_verified}{{24}{2024{d}}{{OpenAI}}{{}}}
\bibcite{QwQ}{{25}{2024{a}}{{Qwen}}{{}}}
\bibcite{qwen2_5}{{26}{2024{b}}{{Qwen}}{{}}}
\bibcite{gpqa}{{27}{2023}{{Rein et~al.}}{{Rein, Hou, Stickland, Petty, Pang, Dirani, Michael, and Bowman}}}
\bibcite{deepseekmath}{{28}{2024}{{Shao et~al.}}{{Shao, Wang, Zhu, Xu, Song, Zhang, Li, Wu, and Guo}}}
\bibcite{alphazero}{{29}{2017{a}}{{Silver et~al.}}{{Silver, Hubert, Schrittwieser, Antonoglou, Lai, Guez, Lanctot, Sifre, Kumaran, Graepel, Lillicrap, Simonyan, and Hassabis}}}
\bibcite{alphago}{{30}{2017{b}}{{Silver et~al.}}{{Silver, Schrittwieser, Simonyan, Antonoglou, Huang, Guez, Hubert, Baker, Lai, Bolton, Chen, Lillicrap, Hui, Sifre, van~den Driessche, Graepel, and Hassabis}}}
\bibcite{snell2024scalingllmtesttimecompute}{{31}{2024}{{Snell et~al.}}{{Snell, Lee, Xu, and Kumar}}}
\bibcite{AlphaGeometryTrinh2024}{{32}{2024}{{Trinh et~al.}}{{Trinh, Wu, Le, He, and Luong}}}
\bibcite{uesato2022solving}{{33}{2022}{{Uesato et~al.}}{{Uesato, Kushman, Kumar, Song, Siegel, Wang, Creswell, Irving, and Higgins}}}
\bibcite{mathshepherd}{{34}{2023}{{Wang et~al.}}{{Wang, Li, Shao, Xu, Dai, Li, Chen, Wu, and Sui}}}
\bibcite{wang2022self}{{35}{2022}{{Wang et~al.}}{{Wang, Wei, Schuurmans, Le, Chi, Narang, Chowdhery, and Zhou}}}
\bibcite{mmlu_pro}{{36}{2024}{{Wang et~al.}}{{Wang, Ma, Zhang, Ni, Chandra, Guo, Ren, Arulraj, He, Jiang, Li, Ku, Wang, Zhuang, Fan, Yue, and Chen}}}
\bibcite{agentless}{{37}{2024}{{Xia et~al.}}{{Xia, Deng, Dunn, and Zhang}}}
\bibcite{xin2024deepseekproverv15harnessingproofassistant}{{38}{2024}{{Xin et~al.}}{{Xin, Ren, Song, Shao, Zhao, Wang, Liu, Zhang, Lu, Du, Gao, Zhu, Yang, Gou, Wu, Luo, and Ruan}}}
\bibcite{IFeval}{{39}{2023}{{Zhou et~al.}}{{Zhou, Lu, Mishra, Brahma, Basu, Luan, Zhou, and Hou}}}
\@writefile{toc}{\contentsline {section}{\numberline {A}贡献与致谢}{20}{appendix.A}\protected@file@percent }
\newlabel{LastPage}{{A}{22}{贡献与致谢}{page.22}{}}
\gdef\lastpage@lastpage{22}
\gdef\lastpage@lastpageHy{22}
\gdef \@abspage@last{22}
